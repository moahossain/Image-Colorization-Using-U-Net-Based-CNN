{"metadata":{"kernelspec":{"language":"python","display_name":"Python 3","name":"python3"},"language_info":{"name":"python","version":"3.10.14","mimetype":"text/x-python","codemirror_mode":{"name":"ipython","version":3},"pygments_lexer":"ipython3","nbconvert_exporter":"python","file_extension":".py"},"kaggle":{"accelerator":"gpu","dataSources":[{"sourceId":9495192,"sourceType":"datasetVersion","datasetId":5777814}],"dockerImageVersionId":30805,"isInternetEnabled":true,"language":"python","sourceType":"notebook","isGpuEnabled":true}},"nbformat_minor":4,"nbformat":4,"cells":[{"cell_type":"code","source":"import os\nimport numpy as np\nimport cv2\nimport matplotlib.pyplot as plt\nimport tensorflow as tf\nfrom tensorflow.keras.models import Model\nfrom tensorflow.keras.optimizers import Adam\nfrom tensorflow.keras import layers\nfrom tensorflow.keras.callbacks import ReduceLROnPlateau, EarlyStopping, ModelCheckpoint\nfrom sklearn.model_selection import train_test_split\nfrom skimage.metrics import structural_similarity as ssim, peak_signal_noise_ratio as psnr\nimport shutil\n\n# Paths to the dataset folders\ngray_image_path = \"/kaggle/input/natural-color-dataset/NCDataset/Gray/\"\ncolor_image_path = \"/kaggle/input/natural-color-dataset/ColorfulOriginal/ColorfulOriginal/\"\nIMAGE_SIZE = 256\n\ndef load_images(grayscale_path, color_path, image_size=(IMAGE_SIZE, IMAGE_SIZE)):\n    grayscale_images = []\n    color_images = []\n    category_names = []\n    valid_extensions = {\".jpg\", \".jpeg\", \".png\"}\n    \n    for category in os.listdir(grayscale_path):\n        gray_dir = os.path.join(grayscale_path, category)\n        color_dir = os.path.join(color_path, category)\n        \n        if os.path.isdir(gray_dir) and os.path.isdir(color_dir):\n            for gray_file in os.listdir(gray_dir):\n                if not os.path.splitext(gray_file)[1].lower() in valid_extensions:\n                    continue\n                \n                gray_image_path_full = os.path.join(gray_dir, gray_file)\n                color_image_path_full = os.path.join(color_dir, gray_file)\n                \n                if os.path.exists(gray_image_path_full) and os.path.exists(color_image_path_full):\n                    gray_img = cv2.imread(gray_image_path_full, cv2.IMREAD_GRAYSCALE)\n                    color_img = cv2.imread(color_image_path_full)\n                    \n                    if gray_img is None or color_img is None:\n                        continue\n                    \n                    gray_img = cv2.resize(gray_img, image_size)\n                    color_img = cv2.resize(color_img, image_size)\n                    \n                    # Convert color images from BGR to RGB\n                    color_img = cv2.cvtColor(color_img, cv2.COLOR_BGR2RGB)\n                    \n                    gray_img = gray_img.astype('float32') / 255.0\n                    color_img = color_img.astype('float32') / 255.0\n                    \n                    gray_img = np.expand_dims(gray_img, axis=-1)\n                    \n                    grayscale_images.append(gray_img)\n                    color_images.append(color_img)\n                    category_names.append(category)\n                    \n    return np.array(grayscale_images), np.array(color_images), np.array(category_names)\n\nprint(\"Grayscale Folder Contents:\", os.listdir(gray_image_path))\nprint(\"Color Folder Contents:\", os.listdir(color_image_path))\n\ngrayscale_images, color_images, category_names = load_images(gray_image_path, color_image_path)\nprint(\"Grayscale Images Shape:\", grayscale_images.shape)\nprint(\"Color Images Shape:\", color_images.shape)\nprint(\"Category Names Shape:\", category_names.shape)\n\n# Split data into training and validation sets\nX_train, X_val, y_train, y_val, category_train, category_val = train_test_split(\n    grayscale_images, color_images, category_names, test_size=0.2, random_state=42\n)\n\nprint(f\"Training Set: {X_train.shape}, {y_train.shape}, {category_train.shape}\")\nprint(f\"Validation Set: {X_val.shape}, {y_val.shape}, {category_val.shape}\")\n\ndef build_unet_colorization_model(input_size=(256, 256, 1)):\n    inputs = layers.Input(input_size)\n    \n    # Encoder\n    conv1 = layers.Conv2D(64, (3,3), activation='relu', padding='same')(inputs)\n    conv1 = layers.Conv2D(64, (3,3), activation='relu', padding='same')(conv1)\n    pool1 = layers.MaxPooling2D(pool_size=(2,2))(conv1)\n    \n    conv2 = layers.Conv2D(128, (3,3), activation='relu', padding='same')(pool1)\n    conv2 = layers.Conv2D(128, (3,3), activation='relu', padding='same')(conv2)\n    pool2 = layers.MaxPooling2D(pool_size=(2,2))(conv2)\n    \n    conv3 = layers.Conv2D(256, (3,3), activation='relu', padding='same')(pool2)\n    conv3 = layers.Conv2D(256, (3,3), activation='relu', padding='same')(conv3)\n    pool3 = layers.MaxPooling2D(pool_size=(2,2))(conv3)\n    \n    conv4 = layers.Conv2D(512, (3,3), activation='relu', padding='same')(pool3)\n    conv4 = layers.Conv2D(512, (3,3), activation='relu', padding='same')(conv4)\n    pool4 = layers.MaxPooling2D(pool_size=(2,2))(conv4)\n    \n    # Bottleneck\n    conv5 = layers.Conv2D(1024, (3,3), activation='relu', padding='same')(pool4)\n    conv5 = layers.Conv2D(1024, (3,3), activation='relu', padding='same')(conv5)\n    \n    # Decoder\n    up6 = layers.UpSampling2D(size=(2,2))(conv5)\n    up6 = layers.Conv2D(512, (2,2), activation='relu', padding='same')(up6)\n    merge6 = layers.concatenate([conv4, up6], axis=3)\n    conv6 = layers.Conv2D(512, (3,3), activation='relu', padding='same')(merge6)\n    conv6 = layers.Conv2D(512, (3,3), activation='relu', padding='same')(conv6)\n    \n    up7 = layers.UpSampling2D(size=(2,2))(conv6)\n    up7 = layers.Conv2D(256, (2,2), activation='relu', padding='same')(up7)\n    merge7 = layers.concatenate([conv3, up7], axis=3)\n    conv7 = layers.Conv2D(256, (3,3), activation='relu', padding='same')(merge7)\n    conv7 = layers.Conv2D(256, (3,3), activation='relu', padding='same')(conv7)\n    \n    up8 = layers.UpSampling2D(size=(2,2))(conv7)\n    up8 = layers.Conv2D(128, (2,2), activation='relu', padding='same')(up8)\n    merge8 = layers.concatenate([conv2, up8], axis=3)\n    conv8 = layers.Conv2D(128, (3,3), activation='relu', padding='same')(merge8)\n    conv8 = layers.Conv2D(128, (3,3), activation='relu', padding='same')(conv8)\n    \n    up9 = layers.UpSampling2D(size=(2,2))(conv8)\n    up9 = layers.Conv2D(64, (2,2), activation='relu', padding='same')(up9)\n    merge9 = layers.concatenate([conv1, up9], axis=3)\n    conv9 = layers.Conv2D(64, (3,3), activation='relu', padding='same')(merge9)\n    conv9 = layers.Conv2D(64, (3,3), activation='relu', padding='same')(conv9)\n    \n    conv10 = layers.Conv2D(3, (1,1), activation='sigmoid')(conv9)\n    \n    model = Model(inputs=inputs, outputs=conv10)\n    \n    return model\n\ndef psnr_metric(y_true, y_pred):\n    return tf.image.psnr(y_true, y_pred, max_val=1.0)\n\nmodel = build_unet_colorization_model()\nmodel.compile(optimizer=Adam(learning_rate=0.001), loss='mse', metrics=['mae', psnr_metric])\n\nmodel.summary()\n\n# Callbacks\ncheckpoint = ModelCheckpoint('best_colorization_model.keras', monitor='val_loss', save_best_only=True, mode='min')\nlr_reduction = ReduceLROnPlateau(monitor='val_loss', patience=5, factor=0.5, min_lr=1e-6)\nearly_stop = EarlyStopping(monitor='val_loss', patience=10, restore_best_weights=True)\n\n# Train the model\nhistory = model.fit(\n    X_train, y_train,\n    validation_data=(X_val, y_val),\n    epochs=50,\n    batch_size=16,\n    callbacks=[checkpoint, lr_reduction, early_stop],\n    verbose=1\n)\n\n# Plot training history in a 3x3 grid (showing all metrics)\nplt.figure(figsize=(15, 15))\nmetrics = ['loss', 'val_loss', 'mae', 'val_mae', 'psnr_metric', 'val_psnr_metric']\nfor i, metric in enumerate(metrics):\n    plt.subplot(3, 3, i+1)\n    plt.plot(history.history.get(metric, []), label=metric)\n    plt.xlabel('Epochs')\n    plt.ylabel(metric)\n    plt.title(f'Training and Validation {metric.upper()}')\n    plt.legend()\nplt.tight_layout()\nplt.savefig('training_history_grid.png')\nplt.show()\n\n# Load the best model\nmodel.load_weights('best_colorization_model.keras')\n\n# Select multiple samples for grid visualization\nnum_samples = 3  # Number of rows\nsample_indices = np.random.choice(len(X_val), num_samples, replace=False)\n\nplt.figure(figsize=(18, 18))\nfor i, idx in enumerate(sample_indices):\n    grayscale_image = X_val[idx].squeeze()\n    ground_truth = y_val[idx]\n    category_name = category_val[idx]\n    \n    # Predict colorized image\n    sample_grayscale = X_val[idx:idx+1]\n    predicted_color = model.predict(sample_grayscale)[0]\n    predicted_color = np.clip(predicted_color, 0, 1)\n    \n    # Compute metrics\n    psnr_val = psnr(ground_truth, predicted_color, data_range=1.0)\n    ssim_val = ssim(ground_truth, predicted_color, channel_axis=-1, data_range=1.0)\n    \n    print(f\"Sample {i+1} - Category: {category_name}, PSNR: {psnr_val:.2f}, SSIM: {ssim_val:.4f}\")\n    \n    # Plot Grayscale Image\n    plt.subplot(num_samples, 3, i*3 + 1)\n    plt.title(f\"Grayscale\\nCategory: {category_name}\")\n    plt.imshow(grayscale_image, cmap='gray')\n    plt.axis('off')\n    \n    # Plot Colorized Image\n    plt.subplot(num_samples, 3, i*3 + 2)\n    plt.title(f\"Colorized\\nPSNR: {psnr_val:.2f}, SSIM: {ssim_val:.4f}\")\n    plt.imshow(predicted_color)\n    plt.axis('off')\n    \n    # Plot Ground Truth\n    plt.subplot(num_samples, 3, i*3 + 3)\n    plt.title(\"Ground Truth\")\n    plt.imshow(ground_truth)\n    plt.axis('off')\n\nplt.tight_layout()\nplt.savefig('colorization_grid.png')\nplt.show()\n\n# Save the model\nshutil.make_archive('best_colorization_model', 'zip', '.', 'best_colorization_model.keras')\n","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2024-12-11T16:40:55.658136Z","iopub.execute_input":"2024-12-11T16:40:55.658729Z"}},"outputs":[{"name":"stdout","text":"Grayscale Folder Contents: ['ChilliGreen', 'Broccoli', 'Orange', 'Tomato', 'Brinjal', 'Pomegranate', 'Plum', 'Apple', 'Carrot', 'Pear', 'Strawberry', 'CapsicumGreen', 'LadyFinger', 'Lemon', 'Cucumber', 'Peach', 'Corn', 'Banana', 'Cherry', 'Potato']\nColor Folder Contents: ['ChilliGreen', 'Broccoli', 'Orange', 'Tomato', 'Brinjal', 'Pomegranate', 'Plum', 'Apple', 'Carrot', 'Pear', 'Strawberry', 'CapsicumGreen', 'LadyFinger', 'Lemon', 'Cucumber', 'Peach', 'Corn', 'Banana', 'Cherry', 'Potato']\n","output_type":"stream"}],"execution_count":null},{"cell_type":"code","source":"","metadata":{"trusted":true},"outputs":[],"execution_count":null}]}